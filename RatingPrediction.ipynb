{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rating Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import pickle as pkl\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# Tools for topic modelling\n",
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "\n",
    "# LDA model\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_non_normalized_ratings = pd.read_csv(\"Preprocessed/non_normalized_ratings.csv\")\n",
    "LDA_dataframe_jokes = pd.read_csv(\"Preprocessed/LDA_dataframe_jokes.csv\")\n",
    "\n",
    "\n",
    "numpy_ratings = dataframe_non_normalized_ratings.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Input File\n",
    "\n",
    "new_jokes = []\n",
    "i=1\n",
    "with open('testfile.txt', 'r') as f:\n",
    "    while(i!= 21):\n",
    "        new_jokes.append([i,f.readline()])\n",
    "        i+=1\n",
    "new_jokes_df = pd.DataFrame(np.array(new_jokes))\n",
    "new_jokes_df.columns=['new_joke_id','joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = [\"---\",\"---|---\",\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Text Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jokeText(text,common_words):\n",
    "    \"\"\"\n",
    "    This function cleans joke text for further preprocesing.\n",
    "    It first gets individual words from only lower case , alphanumeric text with no extra whitespaces\n",
    "    then it removes all common words and joins the left out words to form new cleaned text of joke\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "    Returns:\n",
    "        string: cleaned text\n",
    "    \"\"\"\n",
    "    words= re.sub(r\"\\s+\", ' ', re.sub(r'[^\\w+\\s]', ' ', text.lower())).strip().split(' ')\n",
    "    new_words = [w for w in words if w not in common_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def lemenize_jokeText(text,common_words):\n",
    "    \"\"\"\n",
    "    This function lemenize joke text for further preprocesing.\n",
    "    It first gets individual words from text\n",
    "    then it lemenizes every word and joins the new words together to form new text of joke\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "    Returns:\n",
    "        string: lemenized joke text\n",
    "    \"\"\"\n",
    "    lemeniza=WordNetLemmatizer()\n",
    "    new_words = [lemeniza.lemmatize(w) for w in word_tokenize(text) if w not in common_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def posTag_jokes(text):\n",
    "    \"\"\"\n",
    "    This function generates postags from joke text for further preprocesing.\n",
    "    It first gets individual words from text\n",
    "    then it finds postag for every word\n",
    "    and then it filters out only nouns and verbs from them and joins them in a string\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "    Returns:\n",
    "        (sting):  a chain of words conatining only nouns and verbs\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating posTags\n",
    "    text = pos_tag(word_tokenize(text), tagset='universal')\n",
    "    # update posTags and filter by posTags\n",
    "    new_word=[]\n",
    "    for i in text:\n",
    "        if len(i[0]) > 1 and (i[1] == 'NOUN' or i[1] == 'VERB'):\n",
    "            new_word.append(i[0])\n",
    "    return ' '.join(new_word)\n",
    "\n",
    "def preprocess_joke(text,common_words):\n",
    "    \"\"\"\n",
    "    This function preprocess joke text to make it ready for Topic modeling\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "\n",
    "    Returns:\n",
    "        (sting):  a chain of words conatining only nouns and verbs\n",
    "    \"\"\"\n",
    "    return posTag_jokes(lemenize_jokeText(clean_jokeText(text,common_words),common_words))\n",
    "\n",
    "def generate_topics(joke_df,common_words):\n",
    "    \"\"\"\n",
    "        Topic modeling process to be done using LDA for new input jokes\n",
    "    Args:\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "    Returns:\n",
    "        joke_new (pd.DataFrame): dataframe of jokes after topic modeling\n",
    "    \"\"\"\n",
    "    # Preprcessing jokes\n",
    "    joke_new=joke_df.copy()\n",
    "    joke_new['Processed_joke']=joke_new['joke'].apply(lambda x: preprocess_joke(x,common_words))\n",
    "    \n",
    "    tokens = [d.split() for d in joke_new['Processed_joke'].tolist()]\n",
    "    dictionary = Dictionary(tokens)\n",
    "    corpus=[dictionary.doc2bow(token) for token in tokens]\n",
    "    \n",
    "    model = LdaModel.load('Models/lda_model')\n",
    "    # model.update(corpus)\n",
    "    # model.save('lda_model/model1')\n",
    "    \n",
    "    # making clusters\n",
    "    verbs_and_nouns = joke_new['Processed_joke'].tolist()\n",
    "    cluster = [model.get_document_topics(dictionary.doc2bow(d.split()), minimum_probability = 0.0) for d in verbs_and_nouns]\n",
    "    joke_new['cluster'] = pd.Series(cluster)\n",
    "    \n",
    "    # Sorting topics by probabilities\n",
    "    sorted_topics = [(sorted(joke_new['cluster'][i],key=itemgetter(1),  reverse=True)) for i in range(len(joke_df))]\n",
    "    joke_new['sorted_topics'] = pd.Series(sorted_topics)\n",
    "    \n",
    "    # Finding Main Topic for each Joke (finding max Probability topic)\n",
    "    maximum_probability_topic = [joke_new['sorted_topics'][i][0][0] for i in range(len(joke_df))]\n",
    "    joke_new['main_topic'] = maximum_probability_topic\n",
    "    return joke_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Rating Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_joke_item(item_rating,corr_joke_df, active_user_mean_rating = 0):\n",
    "    \"\"\"\n",
    "    Predicts the joke rating for the joke id \n",
    "    Args:\n",
    "        item_rating (pd.DataFrame): average rating of every joke to be considered\n",
    "        corr_joke_df (np.array):  array of correlation for every related  joke to be considered\n",
    "        active_user_mean_rating (float): current joke rating of user -> No mean rating yet, so 0\n",
    "    Returns:\n",
    "        score (float): new joke rating\n",
    "    \"\"\"\n",
    "    t1, t2 = 0, 0\n",
    "    for similarity, norm_rating in zip(corr_joke_df, item_rating):\n",
    "        t1+= norm_rating * similarity\n",
    "        t2+= similarity\n",
    "        \n",
    "    score =active_user_mean_rating if t2==0 else (t1 + active_user_mean_rating)/t2\n",
    "    return score\n",
    "\n",
    "def generate_item_rating(user_ratings,joke_list):\n",
    "    \"\"\"\n",
    "    Generates average rating of every joke to be considered\n",
    "    Args:\n",
    "        user_ratings (np.array): numpy array of user ratings\n",
    "        joke_list (list<int>): list of jokes to be considered\n",
    "\n",
    "    Returns:\n",
    "        item_rating (list<float.)>: list of average ratings of jokes\n",
    "    \"\"\"\n",
    "    item_rating=[]\n",
    "    bool_to_check= (user_ratings.ndim==1)\n",
    "    for joke in joke_list:\n",
    "        if joke not in range(100):\n",
    "            item_rating.append(0)\n",
    "        else:\n",
    "            item_rating.append(user_ratings[int(2+joke)] if (bool_to_check) else np.mean([i for i in user_ratings[:,int(2+joke)] if i!=0]))\n",
    "    return item_rating\n",
    "\n",
    "def generate_corelationMatrix(input_row,joke_df):\n",
    "    \"\"\"\n",
    "    Generates a sorted correlation matrix for an input joke row for all given jokes in the dataset\n",
    "    Args:\n",
    "        input_row (pd.DataFrame): row of the input joke dataframe\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "    Returns:\n",
    "        list_corr_i (np.Array): matrix where first element represents joke_id and second element represets the pearson coefficient of similarity sorted in increasing order\n",
    "    \"\"\"\n",
    "    v1=0\n",
    "    cluster=input_row['cluster']\n",
    "    for i in cluster:\n",
    "        v1+=i[1]*i[1]\n",
    "    list_corr_i=[]\n",
    "    for _,row in joke_df.iterrows():\n",
    "        cv=0\n",
    "        vj=0\n",
    "        row_cluster=ast.literal_eval(row['cluster'])\n",
    "        for k in range(len(cluster)):\n",
    "            val=row_cluster[k][1]\n",
    "            cv+=cluster[k][1]*val\n",
    "            vj+=val*val\n",
    "        if vj==0:\n",
    "            list_corr_i.append([row['joke_id'],0])\n",
    "        else:\n",
    "            list_corr_i.append([row['joke_id'],(cv/((v1**0.5)*(vj**0.5)))])\n",
    "    list_corr_i=np.array(list_corr_i)\n",
    "    list_corr_i=list_corr_i[list_corr_i[:,1].argsort()]\n",
    "    return list_corr_i\n",
    "\n",
    "def predict_new_rating(user_ratings,input_df1,joke_df,common_words,joke_coreelation_threshold=0):\n",
    "    \"\"\"\n",
    "    Generates predicted ratings for new input jokes\n",
    "    Args:\n",
    "        user_ratings (np.array): numpy array of user ratings\n",
    "        input_df1 (pd.DataFrame): dataframe of input jokes\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "        common_words (list): list of common words to be removed from joke \n",
    "        joke_coreelation_threshold (float) : threshold for joke corelation\n",
    "    Returns:\n",
    "        input_df1 (pd.DataFrame): dataframe of input jokes with new ratings\n",
    "    \"\"\"\n",
    "    # Generating topics for input jokes\n",
    "    new_joke_df=generate_topics(input_df1,common_words)\n",
    "    list_new_ratings=[]\n",
    "    for i in range(len(new_joke_df)):\n",
    "        # Generating correlation matrix for every joke\n",
    "        matrix=generate_corelationMatrix(new_joke_df.loc[i],joke_df)\n",
    "        index=0\n",
    "        while(index<matrix.shape[0] and matrix[index,1]<joke_coreelation_threshold):\n",
    "            index+=1\n",
    "        matrix=matrix[index:]\n",
    "        # calculating Rating for every joke using correlation matrix with threshold\n",
    "        item_ratings=generate_item_rating(user_ratings.to_numpy(),matrix[:,0])\n",
    "        list_new_ratings.append(score_joke_item(item_ratings,matrix[:,1]))\n",
    "        \n",
    "    # adding Raings to input dataframe\n",
    "    input_df1['new_rating']=list_new_ratings\n",
    "    \n",
    "    return input_df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **User History Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corelationrow(active_user,passive_user_dataset,n1):\n",
    "    \"\"\"\n",
    "    Generates a sorted correlation matrix for an active user for all given passive users\n",
    "    matrix row structure => 0th index: pasive user_id 1st index: its pearson's corelation coefficient with active user\n",
    "    Args:\n",
    "        active_user (int): Contains the user_id of the active user\n",
    "        passive_user_dataset (list<int>): Contains the list of user_ids of the passive users\n",
    "        n1 (np.array): matrix of database containing joke rattings for every user\n",
    "    Returns:\n",
    "        list_corr_i (np.Array): matrix where first ellement represents user id of passive user and second element represets the pearson coefficient of similarity sorted in increasing order\n",
    "    \"\"\"\n",
    "    list_corr_i=[]\n",
    "    for j in passive_user_dataset:\n",
    "        # calculating pearson's co-relation coefficient between active_user and j (A passive_user)\n",
    "        cv=0\n",
    "        vi=0\n",
    "        vj=0\n",
    "        for k in range(2,102):\n",
    "            cv+=n1[active_user-1][k]*n1[j-1][k]\n",
    "            vi+=n1[active_user-1][k]*n1[active_user-1][k]\n",
    "            vj+=n1[j-1][k]*n1[j-1][k]\n",
    "        list_corr_i.append([j,(cv/((vi**0.5)*(vj**0.5)))])\n",
    "    list_corr_i=np.array(list_corr_i)\n",
    "    list_corr_i=list_corr_i[list_corr_i[:,1].argsort()]\n",
    "    return list_corr_i\n",
    "\n",
    "def df_split(df,threshold):\n",
    "    \"\"\"\n",
    "    Splits df['user_id] in two different parts based on a threshold of number of jokes rated\n",
    "    Args:\n",
    "        df (pd.DataFrame): joke rating dataframe\n",
    "        threshold (int): threshold of number of jokes rated\n",
    "    Returns:\n",
    "        df_dense (pd.DataFrame): dataframe having user_id's of only those users which have rated jokes above or equal to threshold\n",
    "        df_sparse (pd.DataFrame): dataframe having user_id's of only those users which have rated jokes below threshold\n",
    "    \"\"\"\n",
    "    df_dense=(df[df['number_of_jokes_rated']>=threshold])['user_id']\n",
    "    df_sparse=(df[df['number_of_jokes_rated']<threshold])['user_id']\n",
    "    return df_dense, df_sparse\n",
    "\n",
    "def score_user_item(item_id, neighbours_df,neighbour_user_similarity, active_user_mean_rating = 0):\n",
    "    \"\"\"\n",
    "    Predicts the joke rating for the joke id \n",
    "    Args:\n",
    "        neighbours_df (pd.DataFrame): Dataframe of neighbours which willl be used to predict the user ratings\n",
    "        neighbour_user_similarity (np.array):  array of correlation where 0th index: pasive user_id 1st index: its pearson's corelation coefficient with active user\n",
    "        active_user_mean_rating (float): current joke rating of user -> No mean rating yet, so 0\n",
    "    Returns:\n",
    "        score (float): new joke rating\n",
    "    \"\"\"\n",
    "    item_rating = neighbours_df[item_id]\n",
    "    t1, t2 = 0, 0\n",
    "    for similarity, norm_rating in zip(neighbour_user_similarity, item_rating):\n",
    "        t1+= norm_rating * similarity\n",
    "        t2+= similarity\n",
    "    score = (t1 + active_user_mean_rating)/t2\n",
    "    return score\n",
    "\n",
    "def predict_ratings(user_id,df,similarity_threshold,no_of_neighbours,n1,passive_user_dataset):\n",
    "    \"\"\"\n",
    "    Predicts the missing joke ratings for the given user and returns the final ratings (of all 100 jokes) for further processing\n",
    "    Args:\n",
    "        user_id (int): id of active user\n",
    "        df (pd.DataFrame): Dataframe of user ratings\n",
    "        similarity_threshold (float): Desiered threshold for similar neigbours\n",
    "        no_of_neighbours(int): Number of neighbours to be considered for rating (nan value indicates that all users of )\n",
    "        n1 (np.array): matrix of database containing joke rattings for every user\n",
    "        passive_user_dataset (list<int>): Contains the list of user_ids of the passive users\n",
    "    Returns:\n",
    "        joke_score (pd.DataFrame): new joke ratings for user\n",
    "    \"\"\"\n",
    "    user_rating=df.loc[user_id-1]\n",
    "    ratings_to_predict=[column for column in df.columns[2:] if(user_rating[column]==0)]\n",
    "    correlation_row=generate_corelationrow(user_id,passive_user_dataset,n1)\n",
    "    \n",
    "    # Find index for first usable corelation row\n",
    "    index=0\n",
    "    while(index<correlation_row.shape[0] and correlation_row[index,1]<similarity_threshold):\n",
    "        index+=1\n",
    "    \n",
    "    neighbours=correlation_row[index:] if(no_of_neighbours!=no_of_neighbours) else(correlation_row[index:])[np.random.choice(correlation_row.shape[0]-index,no_of_neighbours,replace=False)]\n",
    "    dataframe_neighbours_unrated_jokes =(df[df['user_id'].isin(neighbours[:, 0])])\n",
    "\n",
    "    \n",
    "    # mechanism of filling joke rattings\n",
    "    joke_score = user_rating.copy()\n",
    "    for column in ratings_to_predict:\n",
    "        score = score_user_item(column, dataframe_neighbours_unrated_jokes, neighbours[:, 1], user_rating[column])\n",
    "        joke_score[column]=score\n",
    "    return joke_score\n",
    "\n",
    "def rpub_recommender(user_id,df,n1,input_df1,joke_df,common_words):\n",
    "    \"\"\"\n",
    "    Recommends new jokes to the user based on his previous ratings\n",
    "    Args:\n",
    "        user_id (int): id of active user\n",
    "        df (pd.DataFrame): Dataframe of user ratings\n",
    "        n1 (np.array): matrix of database containing joke rattings for every user\n",
    "        input_df1 (pd.DataFrame): dataframe of input jokes\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "        common_words (list): list of common words to be removed from joke\n",
    "    Returns:\n",
    "        input_df1 (pd.DataFrame): dataframe of input jokes with new ratings\n",
    "    \"\"\"\n",
    "    threshold_no_of_ratings=100\n",
    "    similarity_threshold=0.1\n",
    "    # could be nan as well for considering all possible neighbours\n",
    "    no_of_neighbours=30\n",
    "    joke_coreelation_threshold=0.8\n",
    "    df_dense,_=df_split(df,threshold_no_of_ratings)\n",
    "    new_joke_score=predict_ratings(user_id,df,similarity_threshold,no_of_neighbours,n1,df_dense)\n",
    "    return predict_new_rating(new_joke_score,input_df1,joke_df,common_words,joke_coreelation_threshold=joke_coreelation_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_1</th>\n",
       "      <th>joke_2</th>\n",
       "      <th>joke_3</th>\n",
       "      <th>joke_4</th>\n",
       "      <th>joke_5</th>\n",
       "      <th>joke_6</th>\n",
       "      <th>joke_7</th>\n",
       "      <th>joke_8</th>\n",
       "      <th>joke_9</th>\n",
       "      <th>joke_10</th>\n",
       "      <th>joke_11</th>\n",
       "      <th>joke_12</th>\n",
       "      <th>joke_13</th>\n",
       "      <th>joke_14</th>\n",
       "      <th>joke_15</th>\n",
       "      <th>joke_16</th>\n",
       "      <th>joke_17</th>\n",
       "      <th>joke_18</th>\n",
       "      <th>joke_19</th>\n",
       "      <th>joke_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.82</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>4.17</td>\n",
       "      <td>-8.98</td>\n",
       "      <td>-4.76</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>-6.75</td>\n",
       "      <td>-7.18</td>\n",
       "      <td>8.45</td>\n",
       "      <td>-7.18</td>\n",
       "      <td>-7.52</td>\n",
       "      <td>-7.43</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>-9.85</td>\n",
       "      <td>-9.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.08</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.37</td>\n",
       "      <td>-2.38</td>\n",
       "      <td>-9.66</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-5.34</td>\n",
       "      <td>8.88</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.75</td>\n",
       "      <td>8.64</td>\n",
       "      <td>4.42</td>\n",
       "      <td>7.43</td>\n",
       "      <td>4.56</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>4.66</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>3.30</td>\n",
       "      <td>-1.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   joke_1  joke_2  joke_3  joke_4  joke_5  joke_6  joke_7  joke_8  joke_9  \\\n",
       "0   -7.82    8.79   -9.66   -8.16   -7.52   -8.50   -9.85    4.17   -8.98   \n",
       "1    4.08   -0.29    6.36    4.37   -2.38   -9.66   -0.73   -5.34    8.88   \n",
       "\n",
       "   joke_10  joke_11  joke_12  joke_13  joke_14  joke_15  joke_16  joke_17  \\\n",
       "0    -4.76    -8.50    -6.75    -7.18     8.45    -7.18    -7.52    -7.43   \n",
       "1     9.22     6.75     8.64     4.42     7.43     4.56    -0.97     4.66   \n",
       "\n",
       "   joke_18  joke_19  joke_20  \n",
       "0    -9.81    -9.85    -9.85  \n",
       "1    -0.68     3.30    -1.21  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataframe_non_normalized_ratings[['joke_'+str(i) for i in range(1,21)]][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>new_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What falls, but never needs a bandage? The rai...</td>\n",
       "      <td>0.759473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I was going to tell you a joke about boxing bu...</td>\n",
       "      <td>0.760047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm not a fan of spring cleaning. Let's be hon...</td>\n",
       "      <td>0.622488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Why did the egg hide? It was a little chicken.\\n</td>\n",
       "      <td>0.325672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What did the dirt say to the rain? If you keep...</td>\n",
       "      <td>0.511384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Why couldn't the sunflower ride its bike? It l...</td>\n",
       "      <td>0.279256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>What's an egg's favorite vacation spot? New Yo...</td>\n",
       "      <td>0.268576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>I ate a sock yesterday. It was very time-consu...</td>\n",
       "      <td>0.352633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>What kind of candy do astronauts like? Mars ba...</td>\n",
       "      <td>0.257238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>I wanted to buy some camo pants but couldn't f...</td>\n",
       "      <td>0.614257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Did you hear that Clinton has announced there ...</td>\n",
       "      <td>0.854743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Q: What do Monica Lewinsky and Bob Dole have i...</td>\n",
       "      <td>0.279255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>One Sunday morning William burst into the livi...</td>\n",
       "      <td>0.558798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>The Pope dies and, naturally, goes to heaven. ...</td>\n",
       "      <td>1.040567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>A woman has twins, and gives them up for adopt...</td>\n",
       "      <td>0.346198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>A man and Cindy Crawford get stranded on a des...</td>\n",
       "      <td>0.618678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Why are there so many Jones's in the phone boo...</td>\n",
       "      <td>1.105297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>How many teddybears does it take to change a l...</td>\n",
       "      <td>0.651053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>The Chukcha (Russian Eskimo) phones up the Rus...</td>\n",
       "      <td>0.641256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>What did the Buddhist say to the hot dog vendo...</td>\n",
       "      <td>0.316958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_joke_id                                               joke  new_rating\n",
       "0            1  What falls, but never needs a bandage? The rai...    0.759473\n",
       "1            2  I was going to tell you a joke about boxing bu...    0.760047\n",
       "2            3  I'm not a fan of spring cleaning. Let's be hon...    0.622488\n",
       "3            4   Why did the egg hide? It was a little chicken.\\n    0.325672\n",
       "4            5  What did the dirt say to the rain? If you keep...    0.511384\n",
       "5            6  Why couldn't the sunflower ride its bike? It l...    0.279256\n",
       "6            7  What's an egg's favorite vacation spot? New Yo...    0.268576\n",
       "7            8  I ate a sock yesterday. It was very time-consu...    0.352633\n",
       "8            9  What kind of candy do astronauts like? Mars ba...    0.257238\n",
       "9           10  I wanted to buy some camo pants but couldn't f...    0.614257\n",
       "10          11  Did you hear that Clinton has announced there ...    0.854743\n",
       "11          12  Q: What do Monica Lewinsky and Bob Dole have i...    0.279255\n",
       "12          13  One Sunday morning William burst into the livi...    0.558798\n",
       "13          14  The Pope dies and, naturally, goes to heaven. ...    1.040567\n",
       "14          15  A woman has twins, and gives them up for adopt...    0.346198\n",
       "15          16  A man and Cindy Crawford get stranded on a des...    0.618678\n",
       "16          17  Why are there so many Jones's in the phone boo...    1.105297\n",
       "17          18  How many teddybears does it take to change a l...    0.651053\n",
       "18          19  The Chukcha (Russian Eskimo) phones up the Rus...    0.641256\n",
       "19          20  What did the Buddhist say to the hot dog vendo...    0.316958"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predict_new_rating(dataframe_non_normalized_ratings, new_jokes_df, LDA_dataframe_jokes, common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>new_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What falls, but never needs a bandage? The rai...</td>\n",
       "      <td>4.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I was going to tell you a joke about boxing bu...</td>\n",
       "      <td>4.013181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm not a fan of spring cleaning. Let's be hon...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Why did the egg hide? It was a little chicken.\\n</td>\n",
       "      <td>3.845758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What did the dirt say to the rain? If you keep...</td>\n",
       "      <td>3.845132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Why couldn't the sunflower ride its bike? It l...</td>\n",
       "      <td>3.845866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>What's an egg's favorite vacation spot? New Yo...</td>\n",
       "      <td>3.845888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>I ate a sock yesterday. It was very time-consu...</td>\n",
       "      <td>4.392884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>What kind of candy do astronauts like? Mars ba...</td>\n",
       "      <td>3.477642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>I wanted to buy some camo pants but couldn't f...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Did you hear that Clinton has announced there ...</td>\n",
       "      <td>3.990133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Q: What do Monica Lewinsky and Bob Dole have i...</td>\n",
       "      <td>3.845866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>One Sunday morning William burst into the livi...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>The Pope dies and, naturally, goes to heaven. ...</td>\n",
       "      <td>5.245101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>A woman has twins, and gives them up for adopt...</td>\n",
       "      <td>3.476764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>A man and Cindy Crawford get stranded on a des...</td>\n",
       "      <td>4.031899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Why are there so many Jones's in the phone boo...</td>\n",
       "      <td>3.988959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>How many teddybears does it take to change a l...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>The Chukcha (Russian Eskimo) phones up the Rus...</td>\n",
       "      <td>4.032155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>What did the Buddhist say to the hot dog vendo...</td>\n",
       "      <td>3.477020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_joke_id                                               joke  new_rating\n",
       "0            1  What falls, but never needs a bandage? The rai...    4.013175\n",
       "1            2  I was going to tell you a joke about boxing bu...    4.013181\n",
       "2            3  I'm not a fan of spring cleaning. Let's be hon...    0.000000\n",
       "3            4   Why did the egg hide? It was a little chicken.\\n    3.845758\n",
       "4            5  What did the dirt say to the rain? If you keep...    3.845132\n",
       "5            6  Why couldn't the sunflower ride its bike? It l...    3.845866\n",
       "6            7  What's an egg's favorite vacation spot? New Yo...    3.845888\n",
       "7            8  I ate a sock yesterday. It was very time-consu...    4.392884\n",
       "8            9  What kind of candy do astronauts like? Mars ba...    3.477642\n",
       "9           10  I wanted to buy some camo pants but couldn't f...    0.000000\n",
       "10          11  Did you hear that Clinton has announced there ...    3.990133\n",
       "11          12  Q: What do Monica Lewinsky and Bob Dole have i...    3.845866\n",
       "12          13  One Sunday morning William burst into the livi...    0.000000\n",
       "13          14  The Pope dies and, naturally, goes to heaven. ...    5.245101\n",
       "14          15  A woman has twins, and gives them up for adopt...    3.476764\n",
       "15          16  A man and Cindy Crawford get stranded on a des...    4.031899\n",
       "16          17  Why are there so many Jones's in the phone boo...    3.988959\n",
       "17          18  How many teddybears does it take to change a l...    0.000000\n",
       "18          19  The Chukcha (Russian Eskimo) phones up the Rus...    4.032155\n",
       "19          20  What did the Buddhist say to the hot dog vendo...    3.477020"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = 10\n",
    "display(rpub_recommender(user_id,dataframe_non_normalized_ratings,numpy_ratings,new_jokes_df,LDA_dataframe_jokes,common_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
