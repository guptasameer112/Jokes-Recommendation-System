{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rating Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "import pickle as pkl\n",
    "\n",
    "# Natural Language Processing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# Tools for topic modelling\n",
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "\n",
    "# LDA model\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataframe_ratings = pd.read_csv(\"Preprocessed/non_normalized_ratings.csv\")\n",
    "LDA_dataframe_jokes = pd.read_csv(\"Preprocessed/LDA_dataframe_jokes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Input File\n",
    "\n",
    "new_jokes = []\n",
    "i=1\n",
    "with open('testfile.txt', 'r') as f:\n",
    "    while(i!= 21):\n",
    "        new_jokes.append([i,f.readline()])\n",
    "        i+=1\n",
    "new_jokes_df = pd.DataFrame(np.array(new_jokes))\n",
    "new_jokes_df.columns=['new_joke_id','joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = [\"---\",\"---|---\",\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Text Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jokeText(text,common_words):\n",
    "    \"\"\"\n",
    "    This function cleans joke text for further preprocesing.\n",
    "    It first gets individual words from only lower case , alphanumeric text with no extra whitespaces\n",
    "    then it removes all common words and joins the left out words to form new cleaned text of joke\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "    Returns:\n",
    "        string: cleaned text\n",
    "    \"\"\"\n",
    "    words= re.sub(r\"\\s+\", ' ', re.sub(r'[^\\w+\\s]', ' ', text.lower())).strip().split(' ')\n",
    "    new_words = [w for w in words if w not in common_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def lemenize_jokeText(text,common_words):\n",
    "    \"\"\"\n",
    "    This function lemenize joke text for further preprocesing.\n",
    "    It first gets individual words from text\n",
    "    then it lemenizes every word and joins the new words together to form new text of joke\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "    Returns:\n",
    "        string: lemenized joke text\n",
    "    \"\"\"\n",
    "    lemeniza=WordNetLemmatizer()\n",
    "    new_words = [lemeniza.lemmatize(w) for w in word_tokenize(text) if w not in common_words]\n",
    "    return ' '.join(new_words)\n",
    "\n",
    "def posTag_jokes(text):\n",
    "    \"\"\"\n",
    "    This function generates postags from joke text for further preprocesing.\n",
    "    It first gets individual words from text\n",
    "    then it finds postag for every word\n",
    "    and then it filters out only nouns and verbs from them and joins them in a string\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "    Returns:\n",
    "        (sting):  a chain of words conatining only nouns and verbs\n",
    "    \"\"\"\n",
    "    \n",
    "    # creating posTags\n",
    "    text = pos_tag(word_tokenize(text), tagset='universal')\n",
    "    # update posTags and filter by posTags\n",
    "    new_word=[]\n",
    "    for i in text:\n",
    "        if len(i[0]) > 1 and (i[1] == 'NOUN' or i[1] == 'VERB'):\n",
    "            new_word.append(i[0])\n",
    "    return ' '.join(new_word)\n",
    "\n",
    "def preprocess_joke(text,common_words):\n",
    "    \"\"\"\n",
    "    This function preprocess joke text to make it ready for Topic modeling\n",
    "\n",
    "    Args:\n",
    "        text (string): input joke text\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "\n",
    "    Returns:\n",
    "        (sting):  a chain of words conatining only nouns and verbs\n",
    "    \"\"\"\n",
    "    return posTag_jokes(lemenize_jokeText(clean_jokeText(text,common_words),common_words))\n",
    "\n",
    "def generate_topics(joke_df,common_words):\n",
    "    \"\"\"\n",
    "        Topic modeling process to be done using LDA for new input jokes\n",
    "    Args:\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "        common_words (list): list of common words to be removed from joke text\n",
    "    Returns:\n",
    "        joke_new (pd.DataFrame): dataframe of jokes after topic modeling\n",
    "    \"\"\"\n",
    "    # Preprcessing jokes\n",
    "    joke_new=joke_df.copy()\n",
    "    joke_new['Processed_joke']=joke_new['joke'].apply(lambda x: preprocess_joke(x,common_words))\n",
    "    \n",
    "    tokens = [d.split() for d in joke_new['Processed_joke'].tolist()]\n",
    "    dictionary = Dictionary(tokens)\n",
    "    corpus=[dictionary.doc2bow(token) for token in tokens]\n",
    "    \n",
    "    model = LdaModel.load('Models/lda_model')\n",
    "    # model.update(corpus)\n",
    "    # model.save('lda_model/model1')\n",
    "    \n",
    "    # making clusters\n",
    "    verbs_and_nouns = joke_new['Processed_joke'].tolist()\n",
    "    cluster = [model.get_document_topics(dictionary.doc2bow(d.split()), minimum_probability = 0.0) for d in verbs_and_nouns]\n",
    "    joke_new['cluster'] = pd.Series(cluster)\n",
    "    \n",
    "    # Sorting topics by probabilities\n",
    "    sorted_topics = [(sorted(joke_new['cluster'][i],key=itemgetter(1),  reverse=True)) for i in range(len(joke_df))]\n",
    "    joke_new['sorted_topics'] = pd.Series(sorted_topics)\n",
    "    \n",
    "    # Finding Main Topic for each Joke (finding max Probability topic)\n",
    "    maximum_probability_topic = [joke_new['sorted_topics'][i][0][0] for i in range(len(joke_df))]\n",
    "    joke_new['main_topic'] = maximum_probability_topic\n",
    "    return joke_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Rating Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_user_item(item_rating,corr_joke_df, active_user_mean_rating = 0):\n",
    "    \"\"\"\n",
    "    Predicts the joke rating for the joke id \n",
    "    Args:\n",
    "        item_rating (pd.DataFrame): average rating of every joke to be considered\n",
    "        corr_joke_df (np.array):  array of correlation for every related  joke to be considered\n",
    "        active_user_mean_rating (float): current joke rating of user -> No mean rating yet, so 0\n",
    "    Returns:\n",
    "        score (float): new joke rating\n",
    "    \"\"\"\n",
    "    t1, t2 = 0, 0\n",
    "    for similarity, norm_rating in zip(corr_joke_df, item_rating):\n",
    "        t1+= norm_rating * similarity\n",
    "        t2+= similarity\n",
    "        \n",
    "    score =active_user_mean_rating if t2==0 else (t1 + active_user_mean_rating)/t2\n",
    "    return score\n",
    "\n",
    "def generate_item_rating(user_ratings,joke_list):\n",
    "    \"\"\"\n",
    "    Generates average rating of every joke to be considered\n",
    "    Args:\n",
    "        user_ratings (np.array): numpy array of user ratings\n",
    "        joke_list (list<int>): list of jokes to be considered\n",
    "\n",
    "    Returns:\n",
    "        item_rating (list<float.)>: list of average ratings of jokes\n",
    "    \"\"\"\n",
    "    item_rating=[]\n",
    "    for joke in joke_list:\n",
    "        if joke not in range(100):\n",
    "            item_rating.append(0)\n",
    "        else:\n",
    "            item_rating.append(np.mean([i for i in user_ratings[:,int(2+joke)] if i!=0]))\n",
    "    return item_rating\n",
    "\n",
    "def generate_corelationMatrix(input_row,joke_df):\n",
    "    \"\"\"\n",
    "    Generates a sorted correlation matrix for an input joke row for all given jokes in the dataset\n",
    "    Args:\n",
    "        input_row (pd.DataFrame): row of the input joke dataframe\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "    Returns:\n",
    "        list_corr_i (np.Array): matrix where first element represents joke_id and second element represets the pearson coefficient of similarity sorted in increasing order\n",
    "    \"\"\"\n",
    "    v1=0\n",
    "    cluster=input_row['cluster']\n",
    "    for i in cluster:\n",
    "        v1+=i[1]*i[1]\n",
    "    list_corr_i=[]\n",
    "    for _,row in joke_df.iterrows():\n",
    "        cv=0\n",
    "        vj=0\n",
    "        row_cluster=ast.literal_eval(row['cluster'])\n",
    "        for k in range(len(cluster)):\n",
    "            val=row_cluster[k][1]\n",
    "            cv+=cluster[k][1]*val\n",
    "            vj+=val*val\n",
    "        if vj==0:\n",
    "            list_corr_i.append([row['joke_id'],0])\n",
    "        else:\n",
    "            list_corr_i.append([row['joke_id'],(cv/((v1**0.5)*(vj**0.5)))])\n",
    "    list_corr_i=np.array(list_corr_i)\n",
    "    list_corr_i=list_corr_i[list_corr_i[:,1].argsort()]\n",
    "    return list_corr_i\n",
    "\n",
    "def predict_new_rating(user_ratings,input_df,joke_df,common_words,joke_coreelation_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Generates predicted ratings for new input jokes\n",
    "    Args:\n",
    "        user_ratings (np.array): numpy array of user ratings\n",
    "        input_df (pd.DataFrame): dataframe of input jokes\n",
    "        joke_df (pd.DataFrame):  dataframe of jokes\n",
    "        common_words (list): list of common words to be removed from joke \n",
    "        joke_coreelation_threshold (float) : threshold for joke corelation\n",
    "    Returns:\n",
    "        input_df (pd.DataFrame): dataframe of input jokes with new ratings\n",
    "    \"\"\"\n",
    "    # Generating topics for input jokes\n",
    "    new_joke_df=generate_topics(input_df,common_words)\n",
    "    list_new_ratings=[]\n",
    "    for i in range(len(new_joke_df)):\n",
    "        # Generating correlation matrix for every joke\n",
    "        matrix=generate_corelationMatrix(new_joke_df.loc[i],joke_df)\n",
    "        index=0\n",
    "        while(index<matrix.shape[0] and matrix[index,1]<joke_coreelation_threshold):\n",
    "            index+=1\n",
    "        matrix=matrix[index:]\n",
    "        # calculating Rating for every joke using correlation matrix with threshold\n",
    "        item_ratings=generate_item_rating(user_ratings.to_numpy(),matrix[:,0])\n",
    "        list_new_ratings.append(score_user_item(item_ratings,matrix[:,1]))\n",
    "        \n",
    "    # adding Raings to input dataframe\n",
    "    input_df['new_rating']=list_new_ratings\n",
    "    \n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_joke_id</th>\n",
       "      <th>joke</th>\n",
       "      <th>new_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What does an atheist say during an orgasm?  \"O...</td>\n",
       "      <td>1.404265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Two men are discussing the age old question: w...</td>\n",
       "      <td>0.579673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arnold Swartzeneger and Sylvester Stallone are...</td>\n",
       "      <td>0.624062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A horse walks into a bar. Bartender says:  \"So...</td>\n",
       "      <td>1.198681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A boy comes home from school and tells his mot...</td>\n",
       "      <td>0.599147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A couple has been married for 75 years. For th...</td>\n",
       "      <td>0.561238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>There was an engineer who had an exceptional g...</td>\n",
       "      <td>0.412504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The graduate with a Science degree asks, \"Why ...</td>\n",
       "      <td>0.893850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Three engineering students were gathered toget...</td>\n",
       "      <td>0.703156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>A guy goes into confession and says to the pri...</td>\n",
       "      <td>0.669508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Did you hear that Clinton has announced there ...</td>\n",
       "      <td>0.439990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Q: What do Monica Lewinsky and Bob Dole have i...</td>\n",
       "      <td>0.439973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>One Sunday morning William burst into the livi...</td>\n",
       "      <td>0.408990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>The Pope dies and, naturally, goes to heaven. ...</td>\n",
       "      <td>0.547152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>A woman has twins, and gives them up for adopt...</td>\n",
       "      <td>0.816645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>A man and Cindy Crawford get stranded on a des...</td>\n",
       "      <td>0.609126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Why are there so many Jones's in the phone boo...</td>\n",
       "      <td>0.277384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>How many teddybears does it take to change a l...</td>\n",
       "      <td>0.297168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>The Chukcha (Russian Eskimo) phones up the Rus...</td>\n",
       "      <td>0.277357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>What did the Buddhist say to the hot dog vendo...</td>\n",
       "      <td>0.560593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_joke_id                                               joke  new_rating\n",
       "0            1  What does an atheist say during an orgasm?  \"O...    1.404265\n",
       "1            2  Two men are discussing the age old question: w...    0.579673\n",
       "2            3  Arnold Swartzeneger and Sylvester Stallone are...    0.624062\n",
       "3            4  A horse walks into a bar. Bartender says:  \"So...    1.198681\n",
       "4            5  A boy comes home from school and tells his mot...    0.599147\n",
       "5            6  A couple has been married for 75 years. For th...    0.561238\n",
       "6            7  There was an engineer who had an exceptional g...    0.412504\n",
       "7            8  The graduate with a Science degree asks, \"Why ...    0.893850\n",
       "8            9  Three engineering students were gathered toget...    0.703156\n",
       "9           10  A guy goes into confession and says to the pri...    0.669508\n",
       "10          11  Did you hear that Clinton has announced there ...    0.439990\n",
       "11          12  Q: What do Monica Lewinsky and Bob Dole have i...    0.439973\n",
       "12          13  One Sunday morning William burst into the livi...    0.408990\n",
       "13          14  The Pope dies and, naturally, goes to heaven. ...    0.547152\n",
       "14          15  A woman has twins, and gives them up for adopt...    0.816645\n",
       "15          16  A man and Cindy Crawford get stranded on a des...    0.609126\n",
       "16          17  Why are there so many Jones's in the phone boo...    0.277384\n",
       "17          18  How many teddybears does it take to change a l...    0.297168\n",
       "18          19  The Chukcha (Russian Eskimo) phones up the Rus...    0.277357\n",
       "19          20  What did the Buddhist say to the hot dog vendo...    0.560593"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predict_new_rating(merged_dataframe_ratings, new_jokes_df, LDA_dataframe_jokes, common_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
